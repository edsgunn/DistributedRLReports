
@article{AlphaGo,
	abstract = {The game of Go has long been viewed as the most challenging of classic games for artificial intelligence owing to its enormous search space and the difficulty of evaluating board positions and moves. Here we introduce a new approach to computer Go that uses `value networks'to evaluate board positions and `policy networks'to select moves. These deep neural networks are trained by a novel combination of supervised learning from human expert games, and reinforcement learning from games of self-play. Without any lookahead search, the neural networks play Go at the level of state-of-the-art Monte Carlo tree search programs that simulate thousands of random games of self-play. We also introduce a new search algorithm that combines Monte Carlo simulation with value and policy networks. Using this search algorithm, our program AlphaGo achieved a 99.8{\%} winning rate against other Go programs, and defeated the human European Go champion by 5 games to 0. This is the first time that a computer program has defeated a human professional player in the full-sized game of Go, a feat previously thought to be at least a decade away.},
	author = {Silver, David and Huang, Aja and Maddison, Chris J. and Guez, Arthur and Sifre, Laurent and van den Driessche, George and Schrittwieser, Julian and Antonoglou, Ioannis and Panneershelvam, Veda and Lanctot, Marc and Dieleman, Sander and Grewe, Dominik and Nham, John and Kalchbrenner, Nal and Sutskever, Ilya and Lillicrap, Timothy and Leach, Madeleine and Kavukcuoglu, Koray and Graepel, Thore and Hassabis, Demis},
	date = {2016/01/01},
	date-added = {2022-11-26 12:09:29 +0000},
	date-modified = {2022-11-26 12:09:29 +0000},
	doi = {10.1038/nature16961},
	id = {Silver2016},
	isbn = {1476-4687},
	journal = {Nature},
	number = {7587},
	pages = {484--489},
	title = {Mastering the game of Go with deep neural networks and tree search},
	url = {https://doi.org/10.1038/nature16961},
	volume = {529},
	year = {2016},
	bdsk-url-1 = {https://doi.org/10.1038/nature16961}}

@article{OpenAIFive,
  author    = {Christopher Berner and
               Greg Brockman and
               Brooke Chan and
               Vicki Cheung and
               Przemyslaw Debiak and
               Christy Dennison and
               David Farhi and
               Quirin Fischer and
               Shariq Hashme and
               Christopher Hesse and
               Rafal J{\'{o}}zefowicz and
               Scott Gray and
               Catherine Olsson and
               Jakub Pachocki and
               Michael Petrov and
               Henrique Pond{\'{e}} de Oliveira Pinto and
               Jonathan Raiman and
               Tim Salimans and
               Jeremy Schlatter and
               Jonas Schneider and
               Szymon Sidor and
               Ilya Sutskever and
               Jie Tang and
               Filip Wolski and
               Susan Zhang},
  title     = {Dota 2 with Large Scale Deep Reinforcement Learning},
  journal   = {CoRR},
  volume    = {abs/1912.06680},
  year      = {2019},
  url       = {http://arxiv.org/abs/1912.06680},
  eprinttype = {arXiv},
  eprint    = {1912.06680},
  timestamp = {Wed, 03 Jun 2020 10:56:28 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1912-06680.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{GeneralisationInRL,
  author    = {Robert Kirk and
               Amy Zhang and
               Edward Grefenstette and
               Tim Rockt{\"{a}}schel},
  title     = {A Survey of Generalisation in Deep Reinforcement Learning},
  journal   = {CoRR},
  volume    = {abs/2111.09794},
  year      = {2021},
  url       = {https://arxiv.org/abs/2111.09794},
  eprinttype = {arXiv},
  eprint    = {2111.09794},
  timestamp = {Mon, 22 Nov 2021 16:44:06 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2111-09794.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@article{MAML,
  author    = {Chelsea Finn and
               Pieter Abbeel and
               Sergey Levine},
  title     = {Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks},
  journal   = {CoRR},
  volume    = {abs/1703.03400},
  year      = {2017},
  url       = {http://arxiv.org/abs/1703.03400},
  eprinttype = {arXiv},
  eprint    = {1703.03400},
  timestamp = {Mon, 13 Aug 2018 16:47:43 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/FinnAL17.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@misc{AlgorithmDistillation,
  doi = {10.48550/ARXIV.2210.14215},
  
  url = {https://arxiv.org/abs/2210.14215},
  
  author = {Laskin, Michael and Wang, Luyu and Oh, Junhyuk and Parisotto, Emilio and Spencer, Stephen and Steigerwald, Richie and Strouse, DJ and Hansen, Steven and Filos, Angelos and Brooks, Ethan and Gazeau, Maxime and Sahni, Himanshu and Singh, Satinder and Mnih, Volodymyr},
  
  keywords = {Machine Learning (cs.LG), Artificial Intelligence (cs.AI), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {In-context Reinforcement Learning with Algorithm Distillation},
  
  publisher = {arXiv},
  
  year = {2022},
  
  copyright = {Creative Commons Attribution 4.0 International}
}
@misc{MiniHack,
  doi = {10.48550/ARXIV.2109.13202},
  
  url = {https://arxiv.org/abs/2109.13202},
  
  author = {Samvelyan, Mikayel and Kirk, Robert and Kurin, Vitaly and Parker-Holder, Jack and Jiang, Minqi and Hambro, Eric and Petroni, Fabio and Küttler, Heinrich and Grefenstette, Edward and Rocktäschel, Tim},
  
  keywords = {Machine Learning (cs.LG), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {MiniHack the Planet: A Sandbox for Open-Ended Reinforcement Learning Research},
  
  publisher = {arXiv},
  
  year = {2021},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}
@article{XLand,
  author    = {Open Ended Learning Team and
               Adam Stooke and
               Anuj Mahajan and
               Catarina Barros and
               Charlie Deck and
               Jakob Bauer and
               Jakub Sygnowski and
               Maja Trebacz and
               Max Jaderberg and
               Micha{\"{e}}l Mathieu and
               Nat McAleese and
               Nathalie Bradley{-}Schmieg and
               Nathaniel Wong and
               Nicolas Porcel and
               Roberta Raileanu and
               Steph Hughes{-}Fitt and
               Valentin Dalibard and
               Wojciech Marian Czarnecki},
  title     = {Open-Ended Learning Leads to Generally Capable Agents},
  journal   = {CoRR},
  volume    = {abs/2107.12808},
  year      = {2021},
  url       = {https://arxiv.org/abs/2107.12808},
  eprinttype = {arXiv},
  eprint    = {2107.12808},
  timestamp = {Tue, 03 Aug 2021 09:18:07 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2107-12808.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@misc{OpenEndedLearning,
  doi = {10.48550/ARXIV.2202.08266},
  
  url = {https://arxiv.org/abs/2202.08266},
  
  author = {Meier, Robert and Mujika, Asier},
  
  keywords = {Machine Learning (cs.LG), Artificial Intelligence (cs.AI), Robotics (cs.RO), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Open-Ended Reinforcement Learning with Neural Reward Functions},
  
  publisher = {arXiv},
  
  year = {2022},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@article{CurriculumLearning,
  doi = {10.48550/ARXIV.2003.04960},
  
  url = {https://arxiv.org/abs/2003.04960},
  
  author = {Narvekar, Sanmit and Peng, Bei and Leonetti, Matteo and Sinapov, Jivko and Taylor, Matthew E. and Stone, Peter},
  
  keywords = {Machine Learning (cs.LG), Artificial Intelligence (cs.AI), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Curriculum Learning for Reinforcement Learning Domains: A Framework and Survey},
  
  publisher = {arXiv},
  
  year = {2020},
  
  copyright = {Creative Commons Attribution 4.0 International}
}
@ARTICLE{NoFreeLunch,
  author={Wolpert, D.H. and Macready, W.G.},
  journal={IEEE Transactions on Evolutionary Computation}, 
  title={No free lunch theorems for optimization}, 
  year={1997},
  volume={1},
  number={1},
  pages={67-82},
  doi={10.1109/4235.585893}
  }



